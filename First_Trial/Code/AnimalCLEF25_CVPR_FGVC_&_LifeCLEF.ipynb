{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "02WxIoAKL9LZ",
        "qdfcgZ_zMFfE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Analysis**"
      ],
      "metadata": {
        "id": "02WxIoAKL9LZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"metadata.csv\")"
      ],
      "metadata": {
        "id": "OWyTZ8xuE1jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDMgyjKyFNbp",
        "outputId": "b0093936-b945-4dd4-aa69-f6bf7eb5bff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15209 entries, 0 to 15208\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     15209 non-null  int64 \n",
            " 1   identity     13074 non-null  object\n",
            " 2   path         15209 non-null  object\n",
            " 3   date         11302 non-null  object\n",
            " 4   orientation  14506 non-null  object\n",
            " 5   species      13821 non-null  object\n",
            " 6   split        15209 non-null  object\n",
            " 7   dataset      15209 non-null  object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 950.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database_df = df[df['split'] == 'database']\n",
        "query_df = df[df['split'] == 'query']"
      ],
      "metadata": {
        "id": "a7te02eqE4Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "database_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCnxxgdUFVzJ",
        "outputId": "2eea053f-bc6d-436b-c65c-93e5c1797005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 13074 entries, 0 to 14708\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     13074 non-null  int64 \n",
            " 1   identity     13074 non-null  object\n",
            " 2   path         13074 non-null  object\n",
            " 3   date         10113 non-null  object\n",
            " 4   orientation  12871 non-null  object\n",
            " 5   species      11686 non-null  object\n",
            " 6   split        13074 non-null  object\n",
            " 7   dataset      13074 non-null  object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 919.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database_df[\"identity\"].info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc4cbQUBIkze",
        "outputId": "5efe949e-1cec-4871-c776-2da11612fc73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "Index: 13074 entries, 0 to 14708\n",
            "Series name: identity\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "13074 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 204.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database_df = pd.read_csv('database_metadata.csv')\n",
        "\n",
        "identity_counts = database_df['identity'].value_counts()\n",
        "single_occurrence_identities = identity_counts[identity_counts == 1].index\n",
        "\n",
        "print(single_occurrence_identities)\n",
        "print()\n",
        "print(len(single_occurrence_identities))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6ugLInsJImm",
        "outputId": "990737f2-472d-45de-edb0-a88836e37618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['SalamanderID2025_250', 'SalamanderID2025_216', 'SalamanderID2025_217',\n",
            "       'SalamanderID2025_221', 'SalamanderID2025_222', 'SalamanderID2025_223',\n",
            "       'SalamanderID2025_224', 'SalamanderID2025_225', 'SalamanderID2025_229',\n",
            "       'SeaTurtleID2022_t103',\n",
            "       ...\n",
            "       'SalamanderID2025_126', 'SalamanderID2025_125', 'SalamanderID2025_124',\n",
            "       'SalamanderID2025_167', 'SalamanderID2025_166', 'SalamanderID2025_163',\n",
            "       'SalamanderID2025_159', 'SalamanderID2025_158', 'SalamanderID2025_154',\n",
            "       'SalamanderID2025_153'],\n",
            "      dtype='object', name='identity', length=317)\n",
            "\n",
            "317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppo-9BUhFZCT",
        "outputId": "842f4268-fac0-4c86-a7d8-077736337719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2135 entries, 3 to 15208\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     2135 non-null   int64 \n",
            " 1   identity     0 non-null      object\n",
            " 2   path         2135 non-null   object\n",
            " 3   date         1189 non-null   object\n",
            " 4   orientation  1635 non-null   object\n",
            " 5   species      2135 non-null   object\n",
            " 6   split        2135 non-null   object\n",
            " 7   dataset      2135 non-null   object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 150.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "database_df.to_csv(\"database_metadata.csv\", index=False)\n",
        "query_df.to_csv(\"query_metadata.csv\", index=False)"
      ],
      "metadata": {
        "id": "-axklKIZE7DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Load the database_metadata.csv\n",
        "database_df = pd.read_csv('database_metadata.csv')\n",
        "\n",
        "# 2. Find identities that appear only once\n",
        "identity_counts = database_df['identity'].value_counts()\n",
        "single_occurrence_identities = identity_counts[identity_counts == 1].index\n",
        "\n",
        "# 3. Split the data:\n",
        "# - Images with identities appearing only once\n",
        "single_occurrence_df = database_df[database_df['identity'].isin(single_occurrence_identities)]\n",
        "print(\"single_occurrence_df:\")\n",
        "single_occurrence_df.info()\n",
        "print()\n",
        "\n",
        "# - Images with identities appearing at least twice\n",
        "normal_df = database_df[~database_df['identity'].isin(single_occurrence_identities)]\n",
        "print(\"normal_df:\")\n",
        "normal_df.info()\n",
        "print()\n",
        "\n",
        "# 4. Perform stratified train/validation split on normal identities\n",
        "train_normal_df, test_normal_df = train_test_split(\n",
        "    normal_df,\n",
        "    test_size=0.2,\n",
        "    stratify=normal_df['identity'],\n",
        "    random_state=42\n",
        ")\n",
        "print(\"train_normal.df:\")\n",
        "train_normal_df.info()\n",
        "print()\n",
        "print(\"test_normal.df:\")\n",
        "test_normal_df.info()\n",
        "print()\n",
        "\n",
        "# 5. Combine all single-occurrence identities + 80% of normal identities into the training set\n",
        "train_df = pd.concat([train_normal_df, single_occurrence_df]).reset_index(drop=True)\n",
        "\n",
        "# 6. Save the CSV files\n",
        "train_df.to_csv('train_database_metadata.csv', index=False)\n",
        "test_normal_df.to_csv('test_database_metadata.csv', index=False)\n",
        "\n",
        "print(f\"Train set: {len(train_df)} images\")\n",
        "print(f\"Test set: {len(test_normal_df)} images\")\n",
        "split = len(test_normal_df)/len(train_df)\n",
        "print(f\"Split: {split}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44v_Fx-vG3kk",
        "outputId": "a541d45a-5a95-4674-91ee-2eab8944252d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "single_occurrence_df:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 317 entries, 678 to 6309\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     317 non-null    int64 \n",
            " 1   identity     317 non-null    object\n",
            " 2   path         317 non-null    object\n",
            " 3   date         308 non-null    object\n",
            " 4   orientation  317 non-null    object\n",
            " 5   species      7 non-null      object\n",
            " 6   split        317 non-null    object\n",
            " 7   dataset      317 non-null    object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 22.3+ KB\n",
            "\n",
            "normal_df:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 12757 entries, 0 to 13073\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     12757 non-null  int64 \n",
            " 1   identity     12757 non-null  object\n",
            " 2   path         12757 non-null  object\n",
            " 3   date         9805 non-null   object\n",
            " 4   orientation  12554 non-null  object\n",
            " 5   species      11679 non-null  object\n",
            " 6   split        12757 non-null  object\n",
            " 7   dataset      12757 non-null  object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 897.0+ KB\n",
            "\n",
            "train_normal.df:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 10205 entries, 12224 to 3256\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     10205 non-null  int64 \n",
            " 1   identity     10205 non-null  object\n",
            " 2   path         10205 non-null  object\n",
            " 3   date         7847 non-null   object\n",
            " 4   orientation  10044 non-null  object\n",
            " 5   species      9327 non-null   object\n",
            " 6   split        10205 non-null  object\n",
            " 7   dataset      10205 non-null  object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 717.5+ KB\n",
            "\n",
            "test_normal.df:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2552 entries, 5070 to 8050\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   image_id     2552 non-null   int64 \n",
            " 1   identity     2552 non-null   object\n",
            " 2   path         2552 non-null   object\n",
            " 3   date         1958 non-null   object\n",
            " 4   orientation  2510 non-null   object\n",
            " 5   species      2352 non-null   object\n",
            " 6   split        2552 non-null   object\n",
            " 7   dataset      2552 non-null   object\n",
            "dtypes: int64(1), object(7)\n",
            "memory usage: 179.4+ KB\n",
            "\n",
            "Train set: 10522 images\n",
            "Test set: 2552 images\n",
            "Split: 0.24253944117088005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train_database_metadata.csv')\n",
        "test_df = pd.read_csv('test_database_metadata.csv')\n",
        "\n",
        "train_identities = set(train_df['identity'].unique())\n",
        "test_identities = set(test_df['identity'].unique())\n",
        "\n",
        "missing_identities = test_identities - train_identities\n",
        "\n",
        "if len(missing_identities) == 0:\n",
        "    print(\"✅ All identities in the test set are present in the train set.\")\n",
        "else:\n",
        "    print(f\"❌ {len(missing_identities)} identities in the test set are missing from the train set!\")\n",
        "    print(\"Missing identities:\")\n",
        "    print(missing_identities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZMy9iF3S7u9",
        "outputId": "ce5b2185-086e-4290-8e8e-4937f74e93cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All identities in the test set are present in the train set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Dataloaders**"
      ],
      "metadata": {
        "id": "qdfcgZ_zMFfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile create_dataloaders.py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "\n",
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, label_encoder, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label_encoder = label_encoder\n",
        "        self.label_decoder = {v: k for k, v in label_encoder.items()}  # reverse mapping\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.data.iloc[idx]['path'])\n",
        "        identity = self.data.iloc[idx]['identity']\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.label_encoder[identity]\n",
        "\n",
        "        return image, label, img_path, identity  # return more info\n",
        "\n",
        "# Root directory where images are located\n",
        "root = './animal-clef-2025'\n",
        "\n",
        "# Simple resize for displaying images\n",
        "transform_display = T.Compose([\n",
        "    T.Resize([384, 384]),\n",
        "])\n",
        "\n",
        "transform = T.Compose([\n",
        "    *transform_display.transforms,\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_csv = \"train_database_metadata.csv\"\n",
        "test_csv = \"test_database_metadata.csv\"\n",
        "\n",
        "train_identities = pd.read_csv(train_csv)['identity'].unique()\n",
        "label_encoder = {identity: idx for idx, identity in enumerate(sorted(train_identities))}\n",
        "\n",
        "# Datasets\n",
        "train_dataset = AnimalDataset(\n",
        "    csv_file=train_csv,\n",
        "    root_dir=root,\n",
        "    label_encoder=label_encoder,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = AnimalDataset(\n",
        "    csv_file=test_csv,\n",
        "    root_dir=root,\n",
        "    label_encoder=label_encoder,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, labels, paths, identities = zip(*batch)\n",
        "    images = torch.stack(images)\n",
        "    labels = torch.tensor(labels)\n",
        "    return images, labels, paths, identities\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of testing batches: {len(test_loader)}\")\n",
        "\n",
        "images, labels, paths, identities = next(iter(train_loader))\n",
        "\n",
        "print(f\"\\nTrain batch - images shape: {images.shape}\")\n",
        "print(f\"Train batch - labels shape: {labels.shape}\")\n",
        "print(f\"Train batch - labels example: {labels[:5]}\")\n",
        "\n",
        "for i in range(len(paths)):\n",
        "    print(f\"[Train] Image Path: {paths[i]} | Label ID: {labels[i].item()} | Identity: {identities[i]}\")\n",
        "\n",
        "images_test, labels_test, paths_test, identities_test = next(iter(test_loader))\n",
        "\n",
        "print(f\"\\nTest batch - images shape: {images_test.shape}\")\n",
        "print(f\"Test batch - labels shape: {labels_test.shape}\")\n",
        "print(f\"Test batch - labels example: {labels_test[:5]}\")\n",
        "\n",
        "for i in range(len(paths_test)):\n",
        "    print(f\"[Test] Image Path: {paths_test[i]} | Label ID: {labels_test[i].item()} | Identity: {identities_test[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0ZPst1vQ-3Q",
        "outputId": "cf19ff92-c1e1-4146-96e8-f1949971c750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting create_dataloaders.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile create_dataloaders.py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, label_encoder, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label_encoder = label_encoder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Build the full path to the image\n",
        "        img_path = os.path.join(self.root_dir, self.data.iloc[idx]['path'])\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply transformations (if any)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Label is the value from \"identity\"\n",
        "        label_str = self.data.iloc[idx]['identity']\n",
        "        label = self.label_encoder[label_str]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Root directory where images are located\n",
        "root = './animal-clef-2025'\n",
        "\n",
        "# Simple resize for displaying images\n",
        "transform_display = T.Compose([\n",
        "    T.Resize([384, 384]),\n",
        "])\n",
        "\n",
        "# Transform for training / evaluation (resize + normalization)\n",
        "transform = T.Compose([\n",
        "    *transform_display.transforms,   # reuse resize step\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_csv = \"train_database_metadata.csv\"\n",
        "test_csv = \"test_database_metadata.csv\"\n",
        "\n",
        "train_identities = pd.read_csv(train_csv)['identity'].unique()\n",
        "label_encoder = {identity: idx for idx, identity in enumerate(sorted(train_identities))}\n",
        "\n",
        "# Datasets\n",
        "train_dataset = AnimalDataset(\n",
        "    csv_file=train_csv,\n",
        "    root_dir=root,\n",
        "    label_encoder=label_encoder,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_dataset = AnimalDataset(\n",
        "    csv_file=test_csv,\n",
        "    root_dir=root,\n",
        "    label_encoder=label_encoder,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "batch_size = 2\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of testing batches: {len(test_loader)}\")\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"\\nTrain batch - images shape: {images.shape}\")\n",
        "print(f\"Train batch - labels shape: {labels.shape}\")\n",
        "print(f\"Train batch - labels example: {labels[:5]}\")\n",
        "\n",
        "images_test, labels_test = next(iter(test_loader))\n",
        "\n",
        "print(f\"\\nTest batch - images shape: {images_test.shape}\")\n",
        "print(f\"Test batch - labels shape: {labels_test.shape}\")\n",
        "print(f\"Test batch - labels example: {labels_test[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iasypuG8_iTF",
        "outputId": "a728985b-0cb6-467d-973e-1a2861189acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing create_dataloaders.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tune**"
      ],
      "metadata": {
        "id": "XdPo24hwTS_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fine_tune_animal_clef.py\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from transformers import get_scheduler\n",
        "import timm\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class AnimalDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, label_encoder, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.label_encoder = label_encoder\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Build the full path to the image\n",
        "        img_path = os.path.join(self.root_dir, self.data.iloc[idx]['path'])\n",
        "\n",
        "        # Open the image\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Apply transformations (if any)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Label is the value from \"identity\"\n",
        "        label_str = self.data.iloc[idx]['identity']\n",
        "        label = self.label_encoder[label_str]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, scheduler, criterion, device, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(dataloader, desc=f\"Training (Epoch {epoch+1})\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    return running_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=f\"Validating (Epoch {epoch+1})\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return running_loss / len(dataloader), accuracy\n",
        "\n",
        "# Root directory where images are located\n",
        "root = './animal-clef-2025'\n",
        "\n",
        "# Transforms for train and validation\n",
        "train_transform = T.Compose([\n",
        "    T.RandomResizedCrop(384, scale=(0.8, 1.0)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(degrees=10),\n",
        "    T.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
        "    T.AutoAugment(policy=T.AutoAugmentPolicy.IMAGENET),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    T.RandomErasing(p=0.25, scale=(0.02, 0.33))\n",
        "])\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize([384, 384]),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_csv = \"train_database_metadata.csv\"\n",
        "test_csv = \"test_database_metadata.csv\"\n",
        "\n",
        "train_identities = pd.read_csv(train_csv)['identity'].unique()\n",
        "label_encoder = {identity: idx for idx, identity in enumerate(sorted(train_identities))}\n",
        "\n",
        "# Datasets\n",
        "train_dataset = AnimalDataset(\n",
        "    csv_file=train_csv,\n",
        "    root_dir=root,\n",
        "    label_encoder=label_encoder,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = AnimalDataset(\n",
        "    csv_file=test_csv,\n",
        "    root_dir=root,\n",
        "    label_encoder=label_encoder,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "model = timm.create_model(\n",
        "    #'vit_large_patch16_384',\n",
        "    #'convnext_xlarge.fb_in22k_ft_in1k_512',\n",
        "    'swin_large_patch4_window12_384',\n",
        "    pretrained=True,\n",
        "    num_classes=len(label_encoder)\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "num_epochs = 10\n",
        "lr = 8e-5\n",
        "weight_decay = 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "num_training_steps = len(train_loader) * num_epochs\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "metrics_csv = \"epoch_metrics.csv\"\n",
        "\n",
        "if not os.path.exists(metrics_csv):\n",
        "    with open(metrics_csv, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"epoch\", \"train_loss\", \"val_loss\", \"val_acc\", \"learning_rate\"])\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "learning_rates = []\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_val_acc = 0.0\n",
        "best_model_path = \"best_model.pth\"\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, criterion, device, epoch)\n",
        "    val_loss, val_acc = validate(model, test_loader, criterion, device, epoch)\n",
        "\n",
        "    current_lr = scheduler.get_last_lr()[0]\n",
        "    learning_rates.append(current_lr)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | \"\n",
        "          f\"Val Acc: {val_acc:.4f} | \"\n",
        "          f\"LR: {current_lr:.8f}\")\n",
        "\n",
        "    with open(metrics_csv, mode='a', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([epoch+1, train_loss, val_loss, val_acc, current_lr])\n",
        "\n",
        "    # Save best model if val_loss decreased and val_acc increased\n",
        "    if val_loss < best_val_loss and val_acc > best_val_acc:\n",
        "        best_val_loss = val_loss\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'label_encoder': label_encoder,\n",
        "        }, best_model_path)\n",
        "        print(f\"✅ Best model saved at epoch {epoch+1} with Val Loss {val_loss:.4f} and Val Acc {val_acc:.4f}\")\n",
        "\n",
        "# Plot Train and Validation Loss\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.savefig(\"loss_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# Plot Validation Accuracy\n",
        "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Validation Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid()\n",
        "plt.savefig(\"accuracy_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# Plot Learning Rate over Epochs\n",
        "plt.plot(learning_rates, label=\"Learning Rate\")\n",
        "plt.legend()\n",
        "plt.title(\"Learning Rate Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.grid()\n",
        "plt.savefig(\"learning_rate_plot.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1QNhxo8TVsG",
        "outputId": "6a195222-a786-4745-d33a-0eb7688b31e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fine_tune_animal_clef.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "sTgFOpoHcj6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile inference_query.py\n",
        "import torch\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_path = \"best_model.pth\"\n",
        "checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "label_encoder = checkpoint['label_encoder']\n",
        "idx_to_label = {v: k for k, v in label_encoder.items()}\n",
        "\n",
        "model = timm.create_model(\n",
        "    'convnext_xlarge.fb_in22k_ft_in1k_384',\n",
        "    pretrained=False,\n",
        "    num_classes=len(label_encoder)\n",
        ")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "def predict(image_path, threshold=0.6):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    image = image.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        conf, preds = probs.max(dim=1)\n",
        "        confidence = conf.item()\n",
        "        predicted_idx = preds.item()\n",
        "\n",
        "    if confidence >= threshold:\n",
        "        predicted_label = idx_to_label[predicted_idx]\n",
        "    else:\n",
        "        predicted_label = \"new_individual\"\n",
        "\n",
        "    return predicted_label, confidence\n",
        "\n",
        "query_csv = \"query_metadata.csv\"\n",
        "query_data = pd.read_csv(query_csv)\n",
        "\n",
        "root = \"./animal-clef-2025\"\n",
        "\n",
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "for idx, row in tqdm(query_data.iterrows(), total=len(query_data), desc=\"Predicting\"):\n",
        "    img_rel_path = row['path']\n",
        "    img_full_path = os.path.join(root, img_rel_path)\n",
        "\n",
        "    try:\n",
        "        pred_label, conf = predict(img_full_path)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Eroare la imaginea {img_full_path}: {e}\")\n",
        "        pred_label, conf = \"error\", 0.0\n",
        "\n",
        "    predictions.append(pred_label)\n",
        "    confidences.append(conf)\n",
        "\n",
        "query_data['identity'] = predictions\n",
        "query_data['confidence'] = confidences\n",
        "\n",
        "output_csv = \"query_with_predictions.csv\"\n",
        "query_data.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"✅ File saved at {output_csv}\")"
      ],
      "metadata": {
        "id": "Y_P6l8DxcnJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5112d84f-24d3-4637-f94d-3e096c228a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing inference_query.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Submission**"
      ],
      "metadata": {
        "id": "0Xi7kMRKpgHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "query_predictions = pd.read_csv('query_with_predictions.csv')\n",
        "\n",
        "submission = query_predictions[['image_id', 'identity']]\n",
        "\n",
        "submission.to_csv('sample_submission.csv', index=False)\n",
        "\n",
        "print(\"✅ sample_submission.csv done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB-nWwj6piT3",
        "outputId": "6744ec0c-24a6-49e9-92ae-8e2707e0f5b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ sample_submission.csv done!\n"
          ]
        }
      ]
    }
  ]
}